import requests
import json
import textwrap
import os
from dotenv import load_dotenv
from typing import List, Dict
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_openai import ChatOpenAI

class EnhancedNewsArticleRAG:
    def __init__(self, openai_api_key, model='gpt-4-turbo'):
        """
        ê³ ê¸‰ ë‰´ìŠ¤ ê¸°ì‚¬ ìƒì„± ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        :param openai_api_key: OpenAI API í‚¤
        :param model: ì‚¬ìš©í•  ì–¸ì–´ ëª¨ë¸
        """
        self.embeddings = OpenAIEmbeddings(api_key=openai_api_key)
        self.llm = ChatOpenAI(
            api_key=openai_api_key, 
            model=model, 
            temperature=0.6  # ì°½ì˜ì„±ê³¼ ì‚¬ì‹¤ì„± ì‚¬ì´ ê· í˜•
        )

    def preprocess_json_data(self, json_data: List[Dict]) -> List[str]:
        """
        JSON ë°ì´í„° ì „ì²˜ë¦¬ ë° ê³ ê¸‰ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        
        :param json_data: ì›ë³¸ JSON ë°ì´í„°
        :return: ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        processed_texts = []
        for item in json_data:
            # ë‹¤ì–‘í•œ í‚¤ì—ì„œ ì •ë³´ ì¶”ì¶œ
            text_parts = []
            
            # ì£¼ìš” ì •ë³´ ì¶”ì¶œ (ì˜ˆì‹œ - ì‹¤ì œ JSON êµ¬ì¡°ì— ë§ê²Œ ì¡°ì • í•„ìš”)
            if 'res_date' in item:
                text_parts.append(f"ë‚ ì§œ: {item['res_date']}")
            
            if 'admin_regn1_name' in item:
                text_parts.append(f"í–‰ì •êµ¬ì—­ëª…: {item['admin_regn1_name']}")
            
            if 'tot' in item:
                text_parts.append(f"ì´ ì‹ ì²­ê±´ìˆ˜: {item['tot']}")
            
            processed_text = " ".join(text_parts)
            processed_texts.append(processed_text)
            print(processed_texts)
        return processed_texts

    def prepare_faiss_database(self, json_data: List[Dict]):
        """
        FAISS ë°ì´í„°ë² ì´ìŠ¤ ê³ ê¸‰ ì¤€ë¹„
        
        :param json_data: ì²˜ë¦¬í•  JSON ë°ì´í„°
        :return: FAISS ë²¡í„° ìŠ¤í† ì–´
        """
        processed_texts = self.preprocess_json_data(json_data)
        vector_store = FAISS.from_texts(processed_texts, self.embeddings)
        return vector_store

    def generate_news_article(self, vector_store, query: str):
        """
        ê³ ê¸‰ RAG ê¸°ì‚¬ ìƒì„±
        
        :param vector_store: FAISS ë²¡í„° ìŠ¤í† ì–´
        :param query: ê¸°ì‚¬ ì£¼ì œ ì¿¼ë¦¬
        :return: ìƒì„±ëœ ê¸°ì‚¬
        """
        # ê´€ë ¨ ë¬¸ì„œ ë” ë§ì´ ê²€ìƒ‰
        relevant_docs = vector_store.similarity_search(query, k=5)
        
        # ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        advanced_prompt_template = PromptTemplate(
            input_variables=['context', 'query'],
            template=textwrap.dedent("""
            ë‹¹ì‹ ì€ ì„¸ê³„ì ì¸ ìˆ˜ì¤€ì˜ ì „ë¬¸ ì €ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ë§¥ë½ì„ ë°”íƒ•ìœ¼ë¡œ {query} ì£¼ì œì— ëŒ€í•œ ì‹¬ë„ ìˆê³  ê· í˜• ì¡íŒ ê¸°ì‚¬ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

            í•µì‹¬ ê°€ì´ë“œë¼ì¸:
            1. ê°ê´€ì ì´ê³  ì¤‘ë¦½ì ì¸ ì‹œê° ìœ ì§€
            2. ë‹¤ì–‘í•œ ê´€ì  ê³ ë ¤
            3. ì‚¬ì‹¤ ê¸°ë°˜ ë³´ë„
            4. ê¹Šì´ ìˆëŠ” ë¶„ì„ ì œê³µ

            ì œê³µëœ ë§¥ë½:
            {context}

            ê¸°ì‚¬ êµ¬ì¡°:
            1. ê°•ë ¥í•˜ê³  ë§¤ë ¥ì ì¸ í—¤ë“œë¼ì¸
            2. ìƒí™©ì˜ í•µì‹¬ì„ ìš”ì•½í•˜ëŠ” ë¦¬ë“œ ë¬¸ë‹¨
            3. ì‹¬ì¸µ ë¶„ì„ (3-4ê°œ ë¬¸ë‹¨)
               - ë°°ê²½ ì„¤ëª…
               - í˜„ì¬ ìƒí™© ë¶„ì„
               - ì ì¬ì  ì˜í–¥ ë° ë¯¸ë˜ ì „ë§
            4. ê· í˜• ì¡íŒ ê²°ë¡ 
            5. ì¶”ê°€ ë§¥ë½ì´ë‚˜ ì „ë¬¸ê°€ ì¸ìš© í¬í•¨

            ìŠ¤íƒ€ì¼ ë…¸íŠ¸:
            - ì „ë¬¸ì ì´ê³  í•™ìˆ ì ì¸ í†¤
            - ëª…í™•í•˜ê³  ê°„ê²°í•œ ì–¸ì–´ ì‚¬ìš©
            - ë³µì¡í•œ ê°œë…ì„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…
            - ê°€ëŠ¥í•œ ê²½ìš° í†µê³„, ì—°êµ¬, ì „ë¬¸ê°€ ì˜ê²¬ ì¸ìš©
            """)
        )

        # ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        context = "\n".join([doc.page_content for doc in relevant_docs])

        # ê¸°ì‚¬ ìƒì„± ì²´ì¸
        article_chain = LLMChain(
            llm=self.llm, 
            prompt=advanced_prompt_template
        )

        # ê¸°ì‚¬ ìƒì„±
        article = article_chain.run(context=context, query=query)

        return article

    def run_news_generation_pipeline(self, url: str, paylaod: str, query: str):
        """
        ë‰´ìŠ¤ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        :param url: JSON ë°ì´í„° URL
        :param query: ê¸°ì‚¬ ì£¼ì œ ì¿¼ë¦¬
        """
        # JSON ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        try: 
            response = requests.post(url, payload)
            data = response.json()
            json_data = data.get('dataList', [])
        except requests.RequestException as e:
            print(f"ë°ì´í„° fetching ì˜¤ë¥˜: {e}")
            return

        # FAISS ë°ì´í„°ë² ì´ìŠ¤ ì¤€ë¹„
        vector_store = self.prepare_faiss_database(json_data)

        # ê³ ê¸‰ ê¸°ì‚¬ ìƒì„±
        news_article = self.generate_news_article(vector_store, query)

        # ê¸°ì‚¬ ì¶œë ¥ ë° í¬ë§¤íŒ…
        print("ğŸ“° ìƒì„±ëœ ì‹¬ì¸µ ë‰´ìŠ¤ ê¸°ì‚¬:\n")
        print(news_article)

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    
    load_dotenv()
    openai_api_key = os.getenv('OPENAI_API_KEY')
    
    # ì‹¤ì œ ì‚¬ìš© ì‹œ ì ì ˆí•œ URLë¡œ ëŒ€ì²´
    url = "https://data.iros.go.kr/cr/rs/selectRgsCsTab.do"
    payload = {
        "rdata_seq": "0000000015",
        "search_real_cls": "",
        "search_sql": "m01",
        "search_type": "02",
        "search_start_date": "202406",
        "search_end_date": "202411",
        "search_regn_cls": "01",
        "search_tab": "grid",
        "search_regn_name": ""
    }
    article = 'ì§€ì—­ë³„ ì†Œìœ ê¶Œ ì´ì „ë“±ê¸° ì‹ ì²­ í˜„í™©'

    news_rag = EnhancedNewsArticleRAG(openai_api_key)
    news_rag.run_news_generation_pipeline(url, payload, article)