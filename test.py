import requests
import faiss
import json
import os
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings  
from langchain_community.vectorstores import FAISS
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_openai import ChatOpenAI

class NewsArticleRAG:
    def __init__(self, openai_api_key):
        """
        Initialize the NewsArticleRAG system
        
        :param openai_api_key: OpenAI API í‚¤
        """
        # OpenAI ì„ë² ë”© ë° ì–¸ì–´ ëª¨ë¸ ì´ˆê¸°í™”
        self.embeddings = OpenAIEmbeddings(api_key=openai_api_key)
        self.llm = ChatOpenAI(
            api_key=openai_api_key, 
            model='gpt-3.5-turbo', 
            temperature=0.7
        )

    def fetch_json_data(self, url, param):
        """
        HTTP ìš”ì²­ìœ¼ë¡œ JSON ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        
        :param url: JSON ë°ì´í„°ë¥¼ ì œê³µí•˜ëŠ” API ì—”ë“œí¬ì¸íŠ¸
        :return: JSON ë°ì´í„°
        """
        response = requests.post(url, param)
        if response.status_code == 200:
            data = response.json()
            return data.get('dataList', [])
        else:
            raise Exception(f"API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")

    def prepare_faiss_database(self, json_data):
        """
        JSON ë°ì´í„°ë¥¼ FAISS ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        
        :param json_data: ì²˜ë¦¬í•  JSON ë°ì´í„°
        :return: FAISS ë²¡í„° ìŠ¤í† ì–´
        """
        # JSON ë°ì´í„° ì „ì²˜ë¦¬ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ
#        texts = [
#            f"{item.get('res_date', '')} {item.get('tot', '')} {item.get('admin_regn1_name', '')}" 
#            for item in json_data
#        ]

        texts = []
        for item in json_data:
#            text = (
#                f"Region: {item['admin_regn1_name']}, "
#                f"Total Applications: {item['tot']}, "
#                f"Date: {item['res_date']}."
#            )
            text_content = json.dumps(item, ensure_ascii=False)
            texts.append(text_content)

        # FAISS ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
        vector_store = FAISS.from_texts(texts, self.embeddings)
        return vector_store

    def generate_news_article(self, vector_store, query):
        """
        RAGë¥¼ í™œìš©í•˜ì—¬ ê¸°ì‚¬ ìƒì„±
        
        :param vector_store: FAISS ë²¡í„° ìŠ¤í† ì–´
        :param query: ê¸°ì‚¬ ì£¼ì œ ì¿¼ë¦¬
        :return: ìƒì„±ëœ ê¸°ì‚¬
        """
        # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        relevant_docs = vector_store.similarity_search(query, k=3)
        
        # ê¸°ì‚¬ ì‘ì„± í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        prompt_template = PromptTemplate(
            input_variables=['context', 'query'],
            template="""
            ë‹¹ì‹ ì€ ì „ë¬¸ ë‰´ìŠ¤ ê¸°ìì…ë‹ˆë‹¤. ë‹¤ìŒ ë§¥ë½ì„ ë°”íƒ•ìœ¼ë¡œ {query} ì£¼ì œì— ëŒ€í•œ ì‹¬ì¸µì ì´ê³  ê°ê´€ì ì¸ ê¸°ì‚¬ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

            ë§¥ë½:
            {context}

            ê¸°ì‚¬ëŠ” ë‹¤ìŒ êµ¬ì¡°ë¥¼ ë”°ë¥´ì„¸ìš”:
            1. ë§¤ë ¥ì ì¸ í—¤ë“œë¼ì¸
            2. ë¦¬ë“œ(ì†Œê°œ) ë¬¸ë‹¨
            3. ì£¼ìš” ë‚´ìš© (3-4ê°œ ë¬¸ë‹¨)
            4. ê²°ë¡  ë° ì „ë§

            ê¸°ì‚¬ ìŠ¤íƒ€ì¼: ê°ê´€ì ì´ê³  ì „ë¬¸ì ì´ë©°, ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë³´ë„
            """
        )

        # ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        context = "\n".join([doc.page_content for doc in relevant_docs])

        # LLM ì²´ì¸ ìƒì„± ë° ê¸°ì‚¬ ìƒì„±
        chain = LLMChain(llm=self.llm, prompt=prompt_template)
        article = chain.run(context=context, query=query)

        return article

    def run_news_generation_pipeline(self, url, payload, query):
        """
        ì „ì²´ ë‰´ìŠ¤ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        :param url: JSON ë°ì´í„° URL
        :param query: ê¸°ì‚¬ ì£¼ì œ ì¿¼ë¦¬
        """
        # JSON ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        json_data = self.fetch_json_data(url, payload)
        if not json_data:
            print("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return

        # FAISS ë°ì´í„°ë² ì´ìŠ¤ ì¤€ë¹„
        vector_store = self.prepare_faiss_database(json_data)

        # ê¸°ì‚¬ ìƒì„±
        news_article = self.generate_news_article(vector_store, query)

        # ê¸°ì‚¬ ì¶œë ¥
        print("ğŸ“° ìƒì„±ëœ ë‰´ìŠ¤ ê¸°ì‚¬:\n")
        print(news_article)

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # OpenAI API í‚¤ ì„¤ì • í•„ìš”
    
    load_dotenv()
    openai_api_key = os.getenv('OPENAI_API_KEY')
    
    # ì˜ˆì‹œ URLê³¼ ì¿¼ë¦¬
    url = "https://data.iros.go.kr/cr/rs/selectRgsCsTab.do"
    payload = {
        "rdata_seq": "0000000015",
        "search_real_cls": "",
        "search_sql": "m01",
        "search_type": "02",
        "search_start_date": "202406",
        "search_end_date": "202411",
        "search_regn_cls": "01",
        "search_tab": "grid",
        "search_regn_name": ""
    }
    query = 'ì§€ì—­ë³„ ì†Œìœ ê¶Œ ì´ì „ë“±ê¸° ì‹ ì²­ í˜„í™©'

    news_rag = NewsArticleRAG(openai_api_key)
    news_rag.run_news_generation_pipeline(url, payload, query)